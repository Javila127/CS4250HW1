# -*- coding: utf-8 -*-
"""indexing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11vtin1MYQpuA3mL_189oVK03hvVf9tJ5
"""

#-------------------------------------------------------------------------
# AUTHOR: James Avila
# FILENAME: indexing.py
# SPECIFICATION: Python program that will read the file collection.csv and output the tf-idf document-term matrix. Conducts stop-word removal and stemming of index terms.
# FOR: CS 4250- Assignment #1
# TIME SPENT: 3 hours
#-----------------------------------------------------------*/
#IMPORTANT NOTE: DO NOT USE ANY ADVANCED PYTHON LIBRARY TO COMPLETE THIS CODE SUCH
#AS numpy OR pandas. You have to work here only with standard arrays
# Importing some Python libraries
import csv

documents = []

# Reading the data in a csv file
with open('collection.csv', 'r') as csvfile:
    reader = csv.reader(csvfile)
    for i, row in enumerate(reader):
        if i > 0:  # skipping the header
            documents.append(row[0])

# Conducting stopword removal.
stopWords = {"i", "she", "her", "they", "their", "and"}
documents = [' '.join([word for word in doc.split() if word.lower() not in stopWords]) for doc in documents]


# Conducting stemming.
stemming = {}
index_terms = set()
for sentence in documents:
    words = sentence.split()
    stemmed_words = []
    for word in words:
        stemmed_word = word.lower()

        if stemmed_word.endswith("s") or stemmed_word.endswith("es"):
            singular_form = stemmed_word[:-1]
            stemming[stemmed_word] = singular_form
            index_terms.add(singular_form)
            stemmed_words.append(singular_form)
        else:
            stemming[stemmed_word] = stemmed_word
            index_terms.add(stemmed_word)
            stemmed_words.append(stemmed_word)

    # Update the documents array with stemmed words
    documents[documents.index(sentence)] = ' '.join(stemmed_words)


# Identifying the index terms.
terms = list(index_terms)

# Building the document-term matrix by using the tf-idf weights.
docTermMatrix = []
for sentence in documents:
    tfidf_vector = []
    words = sentence.split()

    for term in terms:
        # Calculate tf-idf for each term in the document
        tf = words.count(term)
        idf = 1 + sum(1 for doc in documents if term in doc)
        tfidf = tf * (idf**-1)

        tfidf_vector.append(tfidf)

    docTermMatrix.append(tfidf_vector)

# Printing the document-term matrix.
print("Document-Term Matrix:")
for i, doc in enumerate(docTermMatrix):
    print(f"Document {i + 1}:", [f"{terms[j]}:{doc[j]:.4f}" for j in range(len(terms))])

'''
Output using collection.csv

Document-Term Matrix:
Document 1: ['dog:0.0000', 'cat:0.6667', 'love:0.2500']
Document 2: ['dog:0.3333', 'cat:0.0000', 'love:0.2500']
Document 3: ['dog:0.3333', 'cat:0.3333', 'love:0.2500']


'''